# 项目未来发展和想法

## c++直连异种数据库

现在多语言的程序架构主要就是因为c++连接公司的异种数据库这个功能个人还没有能力搭建

目前仅实现了mysql、mongo和sqlserver的部分版本连接，本质上还是通过odbc来，性能上非常捉急

这个功能如果要是可以实现最好，后端数据同步部分可以全部使用c++来实现，但是如果无法实现也有对应的其他解决办法

所以该项功能不是很紧急，等闲下来再说

## sync部分实现由process派发对应的sql，也就是动态sql生成，实现增量更新的最后一环

这部分是最容易实际上也是最紧急的。

全量的数据更新实际上是非常浪费也没有必要的，我们目前的几乎所有业务数据不是仅作增加不做删除，还有就是拥有修改时间这个字段三种。

对于不做删除的变更表，仅通过id就可以判断出需要新增的数据，通过运行时动态生成sql来实现仅从数据库提取对应的更新数据，这样我们实际上需要同步的数据量可以说是非常少，对于更新那么频繁的表可以做到5分钟一更新，变更频繁的表，考虑到公司业务系统的并发量也做不到太多，延迟到30分钟基本上就可以。

对于非侵入式实现变更查询，基本只能做定时轮询，好在数据量不是很大，只查询id和修改时间加在一起也不会对系统造成什么太大压力，尤其是索引这种热点数据一般都在对应业务系统机器的内存当中，或者redis缓存，查询比较快，网络io的瓶颈也不是很重。

对于添加修改时间的，也只需要将id和修改时间的字符串拼接起来做比对就好。

对于我们自己的缓存数据库的写入，应当制作插入不做更新，本系统的id由数据库主键自动生成保持唯一性，通过留存不同修改日期的数据来记录变更历史，基本上我们的数据除了bom之外都不到需要分库分表的地步。

对于目前数据结构的变更虽然有一些但不是很大，只是编写dag调度配置文件的时候会更加痛苦一些，写得更多了。

## 网页生成dag配置

实际上我们的dag配置已经可以算是dsl（领域专属语言）了，最好写一个web端页面可视化的变更dag调度图，这象不是重点也不紧急。

## simd优化

主要把json的解析和生成优化一下，这部分由于改动太多，回头再议。

不过据网上的研究报告和论文，平均能或者24倍的性能提升，等什么时候计算到瓶颈了再说。


## TBB 并行优化（已完成）

主要就是将大部分独立for循环，还有一些容器，内存分配部分换成tbb提供的脚手架

## 数据同步状态监控，走企业微信，后续做自动化运维

写一个程序根据数据库中的日志实时监控数据同步的状态，发现问题和不正常日志来发短信。

后续的进步就是自动化处理异常，不过大部分问题都能通过重启解决，做好异常处理就问题不大。

## devops

这部分主要得等自建填报表单程序完成，就可以埋后门在里面，做贯通内外网的持续集成和持续部署了，先不着急，把程序完善好再说，后续可能没有这么多的变更需求。



